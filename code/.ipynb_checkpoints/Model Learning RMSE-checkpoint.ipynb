{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865e8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random as rn\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d102e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(35)\n",
    "rn.seed(35)\n",
    "tf.random.set_seed(35)\n",
    "#print(device_lib.list_local_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc5946a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/BG Ex data/\"\n",
    "data = np.load(\"../../data/BG_Fold_Info.npz\", allow_pickle=True)\n",
    "\n",
    "train_files = data[\"train\"]\n",
    "test_files = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96eefda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param12 = {\n",
    "    \"FOLD_NUM\": [i for i in range(10)],\n",
    "    \"SEQ_LEN\": [12],\n",
    "    \"BATCH_SIZE\": [128, 256],\n",
    "    \"HIDDEN\": [12, 24, 36]\n",
    "}\n",
    "\n",
    "param24 = {\n",
    "    \"FOLD_NUM\": [i for i in range(10)],\n",
    "    \"SEQ_LEN\": [24],\n",
    "    \"BATCH_SIZE\": [128, 256],\n",
    "    \"HIDDEN\": [24, 48, 72]\n",
    "}\n",
    "\n",
    "param36 = {\n",
    "    \"FOLD_NUM\": [i for i in range(10)],\n",
    "    \"SEQ_LEN\": [36],\n",
    "    \"BATCH_SIZE\": [128, 256],\n",
    "    \"HIDDEN\": [36, 72, 108]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c392f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dict_):\n",
    "    return pd.DataFrame([row for row in product(*dict_.values())], columns=dict_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92cd79aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOLD_NUM</th>\n",
       "      <th>SEQ_LEN</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>HIDDEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>256</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>256</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>128</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>128</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>256</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>256</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>256</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FOLD_NUM  SEQ_LEN  BATCH_SIZE  HIDDEN\n",
       "0           0       12         128      12\n",
       "1           0       12         128      24\n",
       "2           0       12         128      36\n",
       "3           0       12         256      12\n",
       "4           0       12         256      24\n",
       "..        ...      ...         ...     ...\n",
       "175         9       36         128      72\n",
       "176         9       36         128     108\n",
       "177         9       36         256      36\n",
       "178         9       36         256      72\n",
       "179         9       36         256     108\n",
       "\n",
       "[180 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = pd.concat([expand_grid(param12), expand_grid(param24), expand_grid(param36)])\n",
    "params.reset_index(inplace=True)\n",
    "params.drop(\"index\", axis=1, inplace=True)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41525637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d9699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_learning:\n",
    "    \n",
    "    def __init__(self, FOLD, SEQ, BATCH, HIDDEN):\n",
    "        \n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        \n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        \n",
    "        self.train_univ = None\n",
    "        self.train_univ = None\n",
    "        \n",
    "        self.test_univ = None\n",
    "        self.test_univ = None\n",
    "        \n",
    "        self.FOLD=FOLD\n",
    "        self.SEQ=SEQ\n",
    "        self.BATCH=BATCH\n",
    "        self.HIDDEN=HIDDEN\n",
    "        \n",
    "    def __del__(self):\n",
    "        \n",
    "        print(\"Remove Success\\n\")\n",
    "        \n",
    "    def Print_params(self):\n",
    "        \n",
    "        print(\"FOLD:\", self.FOLD)\n",
    "        print(\"SEQ:\", self.SEQ)\n",
    "        print(\"BATCH:\", self.BATCH)\n",
    "        print(\"HIDDEN:\", self.HIDDEN)\n",
    "        \n",
    "    def Add_data(self):\n",
    "        \n",
    "        train_data = []\n",
    "        train_x, train_y = [], []\n",
    "        \n",
    "        for file in train_files[self.FOLD]:\n",
    "            train_data.append(np.load(file_path+file+\".npz\"))\n",
    "            \n",
    "        for i in range(len(train_data)):\n",
    "            train_x.append(train_data[i][\"gen\"+str(self.SEQ)])\n",
    "            train_y.append(train_data[i][\"y\"+str(self.SEQ)].astype(np.float32))\n",
    "            \n",
    "        test_data = []\n",
    "        test_x, test_y = [], []\n",
    "        \n",
    "        for file in test_files[self.FOLD]:\n",
    "            test_data.append(np.load(file_path+file+\".npz\"))\n",
    "            \n",
    "        for i in range(len(test_data)):\n",
    "            test_x.append(test_data[i][\"gen\"+str(self.SEQ)])\n",
    "            test_y.append(test_data[i][\"y\"+str(self.SEQ)].astype(np.float32))\n",
    "            \n",
    "        self.train_x = np.concatenate(train_x).reshape(-1, self.SEQ, 1)\n",
    "        self.train_y = np.concatenate(train_y).reshape(-1, 1)\n",
    "        \n",
    "        self.test_x = np.concatenate(test_x).reshape(-1, self.SEQ, 1)\n",
    "        self.test_y = np.concatenate(test_y).reshape(-1, 1)\n",
    "            \n",
    "    def Print_data(self):\n",
    "        \n",
    "        print(\"Train:\", self.train_x.shape, self.train_y.shape)\n",
    "        print(\"Test:\", self.test_x.shape, self.test_y.shape)\n",
    "        \n",
    "    def Stack_data(self):\n",
    "\n",
    "        train_univ = tf.data.Dataset.from_tensor_slices((self.train_x, self.train_y))\n",
    "        self.train_univ = train_univ.cache().shuffle(len(self.train_x)).batch(self.BATCH).repeat()\n",
    "\n",
    "        test_univ = tf.data.Dataset.from_tensor_slices((self.test_x, self.test_y))\n",
    "        self.test_univ = test_univ.batch(self.BATCH).repeat()\n",
    "        \n",
    "    def RNN_learning(self):\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        with tf.device('/CPU:0'):\n",
    "            rnn_model = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.SimpleRNN(self.HIDDEN, input_shape=self.train_x.shape[-2:]),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            rnn_model.compile(optimizer=\"adam\", loss=root_mean_squared_error)\n",
    "        \n",
    "        \n",
    "            rnn_model.fit(self.train_univ,\n",
    "                          epochs=100,\n",
    "                          steps_per_epoch=int(len(self.train_x)/self.BATCH),\n",
    "                          validation_data=self.test_univ,\n",
    "                          validation_steps=int(len(self.test_x)/self.BATCH))\n",
    "        \n",
    "        print(\"RNN learn complete\")\n",
    "        \n",
    "        rnn_model.save(\"../../model/Fold\"+str(self.FOLD)+\"/RNN_\"+str(self.SEQ)+\"_\"+str(self.HIDDEN)+\"_\"+str(self.BATCH)+\".h5\")\n",
    "\n",
    "    def LSTM_learning(self):\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        lstm_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.LSTM(self.HIDDEN, input_shape=self.train_x.shape[-2:]),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        lstm_model.compile(optimizer=\"adam\", loss=root_mean_squared_error)\n",
    "\n",
    "        lstm_model.fit(self.train_univ,\n",
    "                       epochs=100,\n",
    "                       steps_per_epoch=int(len(self.train_x)/self.BATCH),\n",
    "                       validation_data=self.test_univ,\n",
    "                       validation_steps=int(len(self.test_x)/self.BATCH))\n",
    "        \n",
    "        print(\"LSTM learn complete\")\n",
    "        \n",
    "        lstm_model.save(\"../../model/Fold\"+str(self.FOLD)+\"/LSTM_\"+str(self.SEQ)+\"_\"+str(self.HIDDEN)+\"_\"+str(self.BATCH)+\".h5\")     \n",
    "    \n",
    "    def STACKLSTM_learning(self):\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        stack_lstm_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.LSTM(self.HIDDEN, input_shape=self.train_x.shape[-2:], return_sequences=True),\n",
    "            tf.keras.layers.LSTM(self.HIDDEN, return_sequences=False),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        stack_lstm_model.compile(optimizer=\"adam\", loss=root_mean_squared_error)\n",
    "\n",
    "        stack_lstm_model.fit(self.train_univ,\n",
    "                             epochs=100,\n",
    "                             steps_per_epoch=int(len(self.train_x)/self.BATCH),\n",
    "                             validation_data=self.test_univ,\n",
    "                             validation_steps=int(len(self.test_x)/self.BATCH))\n",
    "        \n",
    "        print(\"STACKLSTM learn complete\")\n",
    "        \n",
    "        stack_lstm_model.save(\"../../model/Fold\"+str(self.FOLD)+\"/STACKLSTM_\"+str(self.SEQ)+\"_\"+str(self.HIDDEN)+\"_\"+str(self.BATCH)+\".h5\")     \n",
    "\n",
    "    def BILSTM_learning(self):\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        bilstm_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Bidirectional(\n",
    "                tf.keras.layers.LSTM(self.HIDDEN),\n",
    "                input_shape=self.train_x.shape[-2:]\n",
    "            ),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        bilstm_model.compile(optimizer=\"adam\", loss=root_mean_squared_error)\n",
    "\n",
    "        bilstm_model.fit(self.train_univ,\n",
    "                         epochs=100,\n",
    "                         steps_per_epoch=int(len(self.train_x)/self.BATCH),\n",
    "                         validation_data=self.test_univ,\n",
    "                         validation_steps=int(len(self.test_x)/self.BATCH))\n",
    "        \n",
    "        print(\"BILSTM learn complete\")\n",
    "        \n",
    "        bilstm_model.save(\"../../model/Fold\"+str(self.FOLD)+\"/BILSTM_\"+str(self.SEQ)+\"_\"+str(self.HIDDEN)+\"_\"+str(self.BATCH)+\".h5\")     \n",
    "\n",
    "    def GRU_learning(self):\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        gru_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.GRU(self.HIDDEN, input_shape=self.train_x.shape[-2:]),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        gru_model.compile(optimizer=\"adam\", loss=root_mean_squared_error)\n",
    "\n",
    "        gru_model.fit(self.train_univ,\n",
    "                      epochs=100,\n",
    "                      steps_per_epoch=int(len(self.train_x)/self.BATCH),\n",
    "                      validation_data=self.test_univ,\n",
    "                      validation_steps=int(len(self.test_x)/self.BATCH))\n",
    "        \n",
    "        print(\"GRU learn complete\")\n",
    "        \n",
    "        gru_model.save(\"../../model/Fold\"+str(self.FOLD)+\"/GRU_\"+str(self.SEQ)+\"_\"+str(self.HIDDEN)+\"_\"+str(self.BATCH)+\".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56e08510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0\n",
      "SEQ: 12\n",
      "BATCH: 128\n",
      "HIDDEN: 12\n",
      "Train: (136038, 12, 1) (136038, 1)\n",
      "Test: (15189, 12, 1) (15189, 1)\n",
      "Epoch 1/100\n",
      "1062/1062 [==============================] - 17s 15ms/step - loss: 190.9856 - val_loss: 185.0892\n",
      "Epoch 2/100\n",
      " 347/1062 [========>.....................] - ETA: 9s - loss: 182.5143"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m ML\u001b[38;5;241m.\u001b[39mPrint_data()\n\u001b[0;32m     24\u001b[0m ML\u001b[38;5;241m.\u001b[39mStack_data()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mML\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRNN_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m ML\u001b[38;5;241m.\u001b[39mLSTM_learning()\n\u001b[0;32m     28\u001b[0m ML\u001b[38;5;241m.\u001b[39mSTACKLSTM_learning()\n",
      "Cell \u001b[1;32mIn[8], line 86\u001b[0m, in \u001b[0;36mModel_learning.RNN_learning\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m rnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39mroot_mean_squared_error)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mrnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_univ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_univ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_x\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN learn complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m rnn_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../model/Fold\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFOLD)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/RNN_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSEQ)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mHIDDEN)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBATCH)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\keras\\engine\\training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3128\u001b[0m   (graph_function,\n\u001b[0;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m     args,\n\u001b[0;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1964\u001b[0m     executing_eagerly)\n\u001b[0;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GluStack\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "directory = \"../../model/\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "directory = \"../../model/Fold\"\n",
    "for i in range(10):\n",
    "    if not os.path.exists(directory+str(i)+\"/\"):\n",
    "        os.makedirs(directory+str(i)+\"/\")\n",
    "\n",
    "for i in range(len(params)):\n",
    "    \n",
    "    ML = Model_learning(\n",
    "        FOLD = params.FOLD_NUM[i],\n",
    "        SEQ = params.SEQ_LEN[i],\n",
    "        BATCH = params.BATCH_SIZE[i],\n",
    "        HIDDEN = params.HIDDEN[i]\n",
    "    )\n",
    "    \n",
    "    ML.Print_params()\n",
    "    \n",
    "    ML.Add_data()\n",
    "    ML.Print_data()\n",
    "    ML.Stack_data()\n",
    "    \n",
    "    ML.RNN_learning()\n",
    "    ML.LSTM_learning()\n",
    "    ML.STACKLSTM_learning()\n",
    "    ML.BILSTM_learning()\n",
    "    ML.GRU_learning()\n",
    "    \n",
    "    del(ML)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe71b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d867a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
